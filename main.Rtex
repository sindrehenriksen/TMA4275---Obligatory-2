\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
% \usepackage{a4wide}
\usepackage{hyperref}
\usepackage{graphicx}
% \usepackage{listings}
\usepackage{bm}

\renewcommand{\thesection}{\arabic{section}.}

% \newcommand\given[1][]{\:#1\vert\:}
% \newcommand{\N}{\mathbb{N}}
% \newcommand{\E}{\mathrm{E}}
% \newcommand{\P}{\mathrm{P}}
% \newcommand{\Var}{\mathrm{Var}}
% \newcommand{\Cov}{\mathrm{Cov}}
% \newcommand{\me}{\mathrm{e}}

\title{TMA4265 Obligatory 2}
\author{Student numbers: 759144, 759135}
\date{Spring 2017}

\begin{document}

\maketitle
\tableofcontents
\newpage

<<echo=FALSE, cache=FALSE>>=
read_chunk("oblig2.R")
options(digits = 2)
@

<<echo=FALSE, message = FALSE, preliminary>>=
@

\section{}
The R-code below fits a Cox proportional hazards model to the provided data without any covariates included and plots the Martingale residuals against the covariates and the transformation $ln(x_1)$. The plots in figure \ref{fig:11} and figure \ref{fig:12} indicate that the relationship between the response variable $y$ and the natural logarithm of the covariate $x_1$ is closer to being linear than the relationship between $y$ and $x_1$.

<<1, fig.align="center", fig.height=3, fig.width=4, fig.cap=c("Plot of the Martingale residuals versus $x_1$.", "Plot of the Martingale residuals versus $ln(x_1)$.", "Plot of the Martingale resiudals versus $x_2$."), fig.pos="htbp">>=
@

\section{}
The covariate $x_2$ is included in the model and the Cox PH model is fitted. The Schoenfeld residuals is then calculated and plotted against the failure times. The Schoenfeld residuals can be used for checking the assumption of proportional hazards. For a correct model one would expect the residuals to be centered around zero. This is not the case in our plot, seen in \ref{fig:21}, where the LOESS line clearly deviates from zero. The assumption of PH might therefore be incorrect. 

<<2, fig.align="center", fig.width=4, fig.height=3, fig.cap=c("The Schoenfeld residuals plotted against the observed failure times. A LOESS for the data is also shown.", "Plot of the log-minus-log of the Kaplan-Meier estimators $\\hat{\\hat{\\beta}}$ for $x_2 = 0$ (black) and $x_2 = 1$ (red) against time.", "Plot of the log-minus-log of the Kaplan-Meier estimators $\\hat{\\hat{\\beta}}$ for $x_2 = 0$ (black) and $x_2 = 1$ (red) against ln(time)."), fig.pos="!htbp">>=
@

Figure \ref{fig:22} shows a plot of the log-minus-log of the Kaplan-Meier estimators $\\hat{\\hat{\\beta}}$ for $x_2 = 0$ and $x_2 = 1$ against time. If the data is from a Weibull-distribution, we would expect the vertical distance between the two lines to be constant and equal to $\beta_2$. The same is true for the plot against $ln(y)$ in figure \ref{fig:23}. Furthermore, the points in the last plot should be on a straight line. We would definitely not reject the possibility of an underlying Weibull-distribution based on any of these tests, especially if the final point (at time $y \approx 14.2$) is disregarded.

\section{}

<<3>>=
@

By looking at the plots of the covariates against their associated Martingale residuals in figure \ref{fig:21} and \ref{fig:22} , we see that taking the logarithm of $x_1$ produces a LOESS line that suggest a linear relation between the covariate and it's residual. We therefore choose to include $ln(x_1)$ as a covariate instead of $x_1$. A new Cox PH model is then fitted using the transformed covariate $ln(x_1)$ and the ordinary covariate $x_2$. The covariate $x_2$ is a binary variable and the model does not benefit from transforming this. Conducting a Wald test and a likelihood ratio test with a null hypotheses stating that $\mathbf{\beta}_k = 0$ leaves us with very low p - values and we therefore reject the null hypothesis. The p - values can be seen by calling \texttt{summary(coxreg\_ex)}, as in the code.

%The p-value found by the Wald test is, while still very small, significantly higher than the one produced by the likelihood ratio test. %The difference in p-values may come from incorrect assumptions regarding the sampling of covariates. 

% Wald test relies on the assumption of a  normally distributed $\beta$ which might not be the case. This is in turn based on the assumption that maximum likelihood estimators are normally distributed when the number of samples increases. The likelihood ratio test does not make any such assumptions

\section{}

<<4, fig.align="center", fig.width=4, fig.height=3, fig.cap=c("caption klap", "caption klap"), fig.pos="!htbp">>=
@

The extended model produces Schoenfeld residuals that seem to be more evenly distributed about zero than the previous model. This suggest that the decision of transforming $x_1$ and including $x_2$ were reasonable choices. The LOESS lines in both plots changes less rapidly and are closer to zero. 

The formal hypothesis test of the PH assumption leads us to reject the null hypothesis that suggests that the PH assumption is not correct. The p-value obtained by calling \texttt{cox.zph} leads us to reject even at significance level 0.01.

\section{}
Here we produce an estimate of the baseline survival function $\hat{R_0}(t)$ using the Breslow estimator (standard for \texttt{coxph()} when there are no ties), and estimates of the survival function $\hat{R}(t)$ for different values of the covariates $x1$ and $x2$.

<<5, fig.align="center", fig.cap="Upper left: Breslow estimator of $\\hat{R_0}(t)$ for the given data. Upper right: Estimate of $\\hat{R}(t)$ for $x1 = 0.2$ and $x2 = 0$ (upper line), $x2 = 1$ (lower line). Lower left:  $x1 = 1$ and $x2 = 0$ (upper line), $x2 = 1$ (lower line). Lower right: $x1 = 5.$", fig.pos="!htbp">>=
@

\section{}

<<6, fig.align="center, fig.cap="Plot of the transformed estimated base survival function against event time", fig.pos="!htbp">>

The baseline survival function  will be of the form

\begin{equation}
    R_0(t) = \exp(-(t/\theta)^{\alpha}/\exp(\mathbf{\beta}^{T}\mathbf{x}))
\end{equation}

if the lifetimes conditional on the covariate values are Weibull - distributed.


The transformation $t^* = \ln(t)$ and $R_0(t^*)^* = \ln(-\ln(R_0(t^*)))$ gives us a linear relation given by

\begin{equation}
    R_0(t^*)^* = {\alpha}(t^* - \ln(\theta)) - \mathbf{\beta}^T\mathbf{x}.
\end{equation}

This enables us to check the assumption of Weibull distributed lifetimes by simply checking whether the curve obtained from plotting $R_0(t^*)^*$ against $t^*$. This is done in figure \ref{fig:61}, and we can clearly see that there's a linear relation between the two quantities. This indicates that the lifetimes conditional on the covariates are Weibull distributed. 

\section{}


\section{}


\section{}

\end{document}